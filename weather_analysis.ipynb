

# 1. download and import NOOA weather data set



#importing file directly from internet
url <- 'https://dax-cdn.cdn.appdomain.cloud/dax-noaa-weather-data-jfk-airport/1.1.4/noaa-weather-sample-data.tar.gz'
download.file(url, destfile = 'jfk_weather_sample.tar.gz')
# for getting the file csv format 
untar('jfk_weather_sample.tar.gz', tar = 'internal')

jfk_weather_sample <- read_csv("jfk_weather_sample.csv",
                    col_types = cols(
                      'HOURLYDewPointTempF' = col_number(),
                      'HOURLYRelativeHumidity' = col_number(),
                       'HOURLYDRYBULBTEMPF' = col_number(),
                      'HOURLYWETBULBTEMPF' = col_number(),
                       'HOURLYPrecip' = col_number(),
                      'HOURLYWindSpeed'= col_number(),
                       'HOURLYSeaLevelPressure' = col_number(),
                      'HOURLYStationPressure' = col_number())) ##code is not running 

#***************************************************************************************************************************
# 2. Extract and Read into Project
jfk_weather_sample <- read.csv("D:/r/week6/noaa-weather-sample-data/jfk_weather_sample.csv")
jfk_weather_sample
head(jfk_weather_sample)

library(tidyverse)
library(tidymodels)
library(rlang)
glimpse(jfk_weather_sample)

#*********************************************************************************************************************************
#3. Select Subset of Columns
#The end goal of this project will be to predict HOURLYprecip (precipitation) using a few 
#other variables. Before you can do this, you first need to preprocess the dataset. Section 3 
#to section 6 focuses on preprocessing.

#The first step in preprocessing is to select a subset of data columns and inspect the column 
#types.

#The key columns that we will explore in this project are:
  
 # HOURLYRelativeHumidity
#HOURLYDRYBULBTEMPF

#HOURLYPrecip
#HOURLYWindSpeed
#HOURLYStationPressure
#Data Glossary:
  
    #  'HOURLYRelativeHumidity' is the relative humidity given to the nearest whole percentage.
   
 #'HOURLYDRYBULBTEMPF' is the dry-bulb temperature and is commonly used as the standard air 
#'temperature reported. It is given here in whole degrees Fahrenheit.

    #'HOURLYPrecip' is the amount of precipitation in inches to hundredths over the past hour.
#' For certain automated stations, precipitation will be reported at sub-hourly intervals 
#' (e.g. every 15 or 20 minutes) as an accumulated amount of all precipitation within the preceding hour. A “T” indicates a trace amount of precipitation.

    #'HOURLYWindSpeed' is the speed of the wind at the time of observation given in miles per hour
#' (mph).

    #'HOURLYStationPressure' is the atmospheric pressure observed at the station during the time
#' of observation. Given in inches of Mercury (in Hg).
#Select those five columns and store the modified dataframe as a new variable.




#we filter out what we want for analysis
weather <- jfk_weather_sample %>%
  select(HOURLYRelativeHumidity, HOURLYDRYBULBTEMPF, HOURLYPrecip, HOURLYWindSpeed, HOURLYStationPressure)


head(weather)

head(weather, 10)
is.na(weather)
anyNA(weather)
is.na(weather$HOURLYPrecip)

weather %>%
  summarise(count = sum(is.na(weather$HOURLYPrecip)))

#for finding number of NA/missing values in all the columns
map(weather,~sum(is.na(.)))
map(jfk_weather_sample,~sum(is.na(.)))

dim(weather)

#******************************************************************************************************************************
#4. Clean Up Columns¶
          #From the dataframe preview above, we can see that the column HOURLYPrecip - which is the hourly measure of 
#precipitation levels - contains both NA and T values. T specifies trace amounts of precipitation (meaning essentially 
#no precipitation), while NA means not available, and is used to denote missing values. Additionally, some values also 
#have "s" at the end of them, indicating that the precipitation was snow.

glimpse(weather)

#Inspect the unique values present in the column HOURLYPrecip (with unique(dataframe$column)) to see these values.

unique(weather$HOURLYPrecip)
glimpse(weather)


    #Having characters in values (like the "T" and "s" that you see in the unique values) will cause problems when you create
#a model because values for precipitation should be numerical. So you need to fix these values that have characters.

#Now, for the column HOURLYPrecip:
  
#  Replace all the T values with "0.0" and
library(dplyr)

# assuming your data is in a dataframe called 'df'
replace_T <- weather %>%
  mutate(HOURLYPrecip = ifelse(HOURLYPrecip == "T", 0.0, HOURLYPrecip))

replace_T_jfk <- jfk_weather_sample %>%
  mutate(HOURLYPrecip = ifelse(HOURLYPrecip == "T", 0.0, HOURLYPrecip))

unique(replace_T$HOURLYPrecip)
unique(replace_T_jfk$HOURLYPrecip)


    #Remove "s" from values like "0.02s". In R, you can use the method str_remove(column, pattern = "s$") to remove the 
#character "s" from the end of values. The "$" tells R to match to the end of values. The pattern is a regex pattern.
#Look at here for more information about regex and matching to strings in R.
#Remember that you can use tidyverse's mutate() to update columns.

library(dplyr)
library(stringr)

# Use mutate and str_remove to remove 's' from the end of values
weather_updated1 <- replace_T %>%
  mutate(HOURLYPrecip = str_remove(HOURLYPrecip, pattern = "s$"))

weather_updated2 <- replace_T_jfk %>%
  mutate(HOURLYPrecip = str_remove(HOURLYPrecip, pattern = "s$"))

# To drop "NA' values from the all column
weather_updated <- weather_updated1 %>%
  drop_na(HOURLYPrecip, HOURLYStationPressure)

dim(weather_updated)
anyNA(weather_updated)

map(weather_updated1,~sum(is.na(.)))


    #You can check your work by checking if unique values of HOURLYPrecip still contain any T or s. Store the modified
#dataframe as a new variable.

unique(weather_updated$HOURLYPrecip)

#******************************************************************************************************************************
#5. Convert Columns to Numerical Types
#Now that you have removed the characters in the HOURLYPrecip column, you can safely covert the column to a numeric type.

#First, check the types of the columns. You will notice that all are dbl (double or numeric) except for HOURLYPrecip,
#which is chr (character or string). Use the glimpse function from Tidyverse
glimpse(weather_updated)

#Convert HOURLYPrecip to the numeric type and store the cleaned dataframe as a new variable.
weather_updated1$HOURLYPrecip <- as.numeric(weather_updated1$HOURLYPrecip)
glimpse(weather_updated1)


replace_na <- weather_updated1 %>% replace_na(list(HOURLYRelativeHumidity = 0,
                                     HOURLYDRYBULBTEMPF = 0,
                                     HOURLYPrecip = 0,
                                     HOURLYWindSpeed = 0,
                                     HOURLYStationPressure = 0))

map(replace_na,~sum(is.na(.)))

#*********************************************************************************************************************************
#6. Rename Columns
#Let's rename the following columns as:

# 'HOURLYRelativeHumidity' to 'relative_humidity'
#'HOURLYDRYBULBTEMPF' to 'dry_bulb_temp_f'
#'HOURLYPrecip' to 'precip'
#'HOURLYWindSpeed' to 'wind_speed'
#'HOURLYStationPressure' to 'station_pressure'

#You can use dplyr::rename(). Then, store the final dataframe as a new variable.
glimpse(weather_updated)

weather_updated_new <- replace_na %>% 
  rename(relative_humidity = HOURLYRelativeHumidity,
         dry_bulb_temp_f = HOURLYDRYBULBTEMPF,
         precip = HOURLYPrecip,
         wind_speed = HOURLYWindSpeed,
         station_pressure = HOURLYStationPressure)

glimpse(weather_updated_new)
map(weather_updated_new, ~sum(is.na(.)))


library(tidymodels)
set.seed(1234)
weather_updated_split <- initial_split(weather_updated_new, prop = 0.8)
training_data1 <- training(weather_updated_split)
testing_data1 <- testing(weather_updated_split)

library(ggplot2)  # Load the ggplot2 package for visualization

# Histograms
ggplot(training_data1) +
  geom_histogram(aes(x = relative_humidity), bins = 20) +
  ggtitle("Histogram of Relative Humidity")

ggplot(training_data1) +
  geom_histogram(aes(x = dry_bulb_temp_f), bins = 20) +
  ggtitle("Histogram of Dry Bulb Temperature")

ggplot(training_data1) +
  geom_histogram(aes(x = precip), bins = 20) +
  ggtitle("Histogram of Precipitation")

ggplot(training_data1) +
  geom_histogram(aes(x = wind_speed), bins = 20) +
  ggtitle("Histogram of Wind Speed")

ggplot(training_data1) +
  geom_histogram(aes(x = station_pressure), bins = 20) +
  ggtitle("Histogram of Station Pressure")

# Box plots
ggplot(training_data1) +
  geom_boxplot(aes(x = "", y = relative_humidity)) +
  ggtitle("Box Plot of Relative Humidity")

ggplot(training_data1) +
  geom_boxplot(aes(x = "", y = dry_bulb_temp_f)) +
  ggtitle("Box Plot of Dry Bulb Temperature")


library(ggplot2)  # Load the ggplot2 package for visualization

# 1. precip ~ relative_humidity
model1 <- lm(precip ~ relative_humidity, data = training_data1)
summary(model1)

ggplot(training_data1, aes(x = relative_humidity, y = precip)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  ggtitle("Precipitation vs Relative Humidity")

# 2. precip ~ dry_bulb_temp_f
model2 <- lm(precip ~ dry_bulb_temp_f, data = training_data1)
summary(model2)

ggplot(training_data1, aes(x = dry_bulb_temp_f, y = precip)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  ggtitle("Precipitation vs Dry Bulb Temperature")

# 3. precip ~ wind_speed
model3 <- lm(precip ~ wind_speed, data = training_data1)
summary(model3)

ggplot(training_data1, aes(x = wind_speed, y = precip)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  ggtitle("Precipitation vs Wind Speed")

# 4. precip ~ station_pressure
model4 <- lm(precip ~ station_pressure, data = training_data1)
summary(model4)

ggplot(training_data1, aes(x = station_pressure, y = precip)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  ggtitle("Precipitation vs Station Pressure")


library(tidymodels)  # Load the tidymodels meta-package
library(glmnet)      # Load the glmnet package for regularized regression

# ------------------------------
# Model 1: L2 Regularization (Ridge Regression)
# ------------------------------

# Create a recipe for preprocessing
recipe <- recipe(precip ~ ., data = training_data1) %>%
  step_normalize(all_predictors())  # Normalize predictors for glmnet

# Create a model specification
model8_spec <- linear_reg(penalty = 0.1, mixture = 0) %>%
  set_engine("glmnet")  # L2 penalty (ridge)

# Create a workflow
workflow8 <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(model8_spec)

# Fit the model using cross-validation
fit8 <- fit(workflow8, training_data1)

# Evaluate performance on the training set
predictions8 <- predict(fit8, training_data1) %>%
  bind_cols(training_data1)  # Combine predictions with original data
mse8 <- mean((predictions8$.pred - predictions8$precip)^2)
rmse8 <- sqrt(mse8)
rsquared8 <- cor(predictions8$.pred, predictions8$precip)^2

# Print performance metrics
cat("Model 8 (L2 Regularization):\n")
cat("MSE:", mse8, "\n")
cat("RMSE:", rmse8, "\n")
cat("R-squared:", rsquared8, "\n\n")

# ------------------------------
# Model 2: L1 Regularization (Lasso Regression)
# ------------------------------

# Model specification for L1 penalty
model9_spec <- linear_reg(penalty = 0.1, mixture = 1)  %>%
  set_engine("glmnet") # L1 penalty (lasso)

model10_spec <- linear_reg(penalty = 0.1, mixture = 0.5)  %>%
  set_engine("glmnet")

library(dplyr)

# ------------------------------
# Model 1: L2 Regularization (Ridge Regression)
# ------------------------------
# Fit the model on training data
fit8 <- fit(workflow8, training_data1)

# Evaluate performance on the training set
predictions8_train <- predict(fit8, training_data1) %>%
  bind_cols(training_data1)
mse8_train <- mean((predictions8_train$.pred - predictions8_train$precip)^2)
rmse8_train <- sqrt(mse8_train)

# Evaluate performance on the testing set
predictions8_test <- predict(fit8, testing_data1) %>%
  bind_cols(testing_data1)
mse8_test <- mean((predictions8_test$.pred - predictions8_test$precip)^2)
rmse8_test <- sqrt(mse8_test)

# ------------------------------
# Model 2: L1 Regularization (Lasso Regression)
# ------------------------------
# Create a workflow for Lasso
workflow9 <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(model9_spec)

# Fit the model
fit9 <- fit(workflow9, training_data1)

# Evaluate performance on the training set
predictions9_train <- predict(fit9, training_data1) %>%
  bind_cols(training_data1)
mse9_train <- mean((predictions9_train$.pred - predictions9_train$precip)^2)
rmse9_train <- sqrt(mse9_train)

# Evaluate performance on the testing set
predictions9_test <- predict(fit9, testing_data1) %>%
  bind_cols(testing_data1)
mse9_test <- mean((predictions9_test$.pred - predictions9_test$precip)^2)
rmse9_test <- sqrt(mse9_test)

# ------------------------------
# Model 3: Combined L1 and L2 Regularization (Elastic Net)
# ------------------------------
# Create a workflow for Elastic Net
workflow10 <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(model10_spec)

# Fit the model
fit10 <- fit(workflow10, training_data1)

# Evaluate performance on the training set
predictions10_train <- predict(fit10, training_data1) %>%
  bind_cols(training_data1)
mse10_train <- mean((predictions10_train$.pred - predictions10_train$precip)^2)
rmse10_train <- sqrt(mse10_train)

# Evaluate performance on the testing set
predictions10_test <- predict(fit10, testing_data1) %>%
  bind_cols(testing_data1)
mse10_test <- mean((predictions10_test$.pred - predictions10_test$precip)^2)
rmse10_test <- sqrt(mse10_test)


# Store results in vectors
model_names <- c("Ridge (L2)", "Lasso (L1)", "Elastic Net (L1 + L2)")
train_rmse <- c(rmse8_train, rmse9_train, rmse10_train)
test_rmse <- c(rmse8_test, rmse9_test, rmse10_test)

# Create a data frame to compare results
comparison_df <- data.frame(
  Model = model_names,
  Train_RMSE = train_rmse,
  Test_RMSE = test_rmse
)

# Print the comparison table
print(comparison_df)
